# 基于大模型如何实现NLP的意图识别
> 意图识别的一些心得体会

### TL;DR
![](https://p.ipic.vip/0taqes.png)

**Assistant API 性价比非常高**

1. Prompt Engineering
    最容易上手的原始形态, 直接在Prompt中添加'技能'清单。 然后通过调整Prompt的内容组织方式来实现意图识别。 好处是简单易懂，坏处是需要大量的人工参与，且不易扩展。

    简单且固定的场景效果还不错，复杂多变且开放式的场景效果看命。 当然好车配好马，用上GPT4效果还是不错的。 可Prompt存在Middle Loss的问题，即中间的词语会被模型忽略，导致意图识别不准确。

    所以，Prompt Engineering的核心在于如何组织Prompt的内容，以及如何解决Middle Loss的问题。 适合快速验证场景，但不适合长期使用。

    ![](https://p.ipic.vip/b8dyk3.png)

2. Function Calling

    Prompt Engineering只能解决[0,1]的问题，如果需要调用对应的API，那么就需要通过其他方式获取参数。 如果使用FC的方式，就可以通过一次调用同时实现意图识别和API参数生成的问题。 看起来好处很多，但是实际上和上面的Prompt Engineering一样，需要大量的人工参与，且不易扩展。 原因在于:

    a. token 窗口仍然存在，所以function calling的描述不能太长。
    b. function calling仍然没有脱离Prompt Engineering的桎梏，所以不能存在相互冲突或者干扰的function描述。
    c. 这种依靠prompt推理的方式，注定受制于middle losss的问题，所以function数量不能太多。同时中间的很容易被选择性遗忘。

    所以，Function Calling的核心在于如何组织Function的内容，以及如何解决Middle Loss的问题。 适合固定场景，不合适开放式场景。同时对API参数要求不高的场景。

    ![](https://p.ipic.vip/aenr0u.png)

3. Fine-tuning(LLM)
    当事情发展到一定规模后，依靠function calling无法解决问题。 就不由自主的选择了Fine-tuning的方式。 Fine-tunnign优点不少(私有数据、耗时短、立竿见影)。但是Fine-tuning的方式也有很多问题，比如:
    
    a. 灾难性遗忘的问题。当微调过多以后，会造成之前的模型遗忘，导致之前的模型无法使用。(如果微调模型仅用于意图识别，这种问题可以忽略)
    b. Fine-tuning的方式，需要大量的数据，而且数据的质量要求很高。否则会造成模型的偏见。
    c. Fine-tuning的方式，需要大量的计算资源。成本偏高（土豪忽略）
    d. 每次想调整都只能重新训练，耗时耗力。如果训练时间过长，那么就会产生无谓的等候。从而造成很高的效果调试成本

    ![](https://p.ipic.vip/k8f151.png)

4. Assistant API
    有没有成本更低的方式，现在看来 Assistant API 是一个不错的选择。 Assistant API 的核心在于将意图识别当作知识库进行对待。 将意图识别的问题转换为知识库的问题。 从而可以通过知识库的方式来解决意图识别的问题。 这种方式优点非常明显:

    a. 在gpt3.5模型上，可以快速的实现意图识别的功能。同时准确率也不错
    b. 在Prompt Engineering的基础上，增加对内容的提取和理解限制，可以有针对性的处理bad case的问题。
    c. 可以通过知识库的方式，来解决灾难性遗忘的问题。
    d. 每次调整只需要调整知识库的内容，不需要重新训练模型。从而大大降低了调试成本。
    e. 如果配合gpt-4，那么可以实现更加复杂的意图识别功能。

    当然，Assistant API也有一些问题: 只能绑定到一个GPT 账户上， 不能实现多账户的功能。 但是这个问题可以通过多个Assistant API来解决。但相应的会增加成本。(当然Fine-tuning也有这个问题)

    ![](https://p.ipic.vip/p9dado.png)

5. Fine-tuning(SLM)
    事情发展到这一步，还可以在优化一下。 对于意图识别来说，使用LLM有些大材小用。 因为意图识别的问题，本质上是一个分类问题。 而LLM是一个生成模型，生成模型的优势在于生成，而不是分类。 所以，可以考虑使用SLM来解决意图识别的问题。 SLM(Small Lanague Model)是我杜撰的名字，意思是小规模语言模型。

    SLM的核心在于，使用小规模的语言模型来解决意图识别的问题。 也就是训练一个端到端的小参数量模型，这个模型功能非常简单就用来做意图识别。 这样做的好处是:

    a. 充分利用移动端(pc端)的GPU设备，可以将推理下沉到移动端(pc端)。减少网络请求，提高响应速度。
    b. 可以学习当前用户的提问习惯，有针对性的学习和理解用户，慢慢的提高准确率
    c. 简单的事情放到客户端完成，复杂的事情放到服务端完成。 从而提高整体的性能。

    ![](https://p.ipic.vip/3gshtx.png)

### 辅助理解

想象一下，你家里有一个超级智能的宠物，比如一只会说话的鹦鹉。这只鹦鹉不仅能模仿你的话，还能理解你说的每一句话的真正含义。这就是大模型在NLP（自然语言处理）中的角色，LLM就像那只超级聪明的鹦鹉。

LLM就像一个巨大的图书馆，里面装满了各种各样的书籍、杂志、报纸，甚至是网络上的博客和推文。它通过阅读（实际上是被训练）这些资料(参考前面几篇文章)，学会了语言的方方面面。

那么，意图识别又是什么呢？简单来说，就是理解人们说话时的真正目的。比如，当你说“家里好冷”，你可能不仅仅是在陈述一个事实，你的真正意图可能是想让房间里的温度调高一点。大模型就像一个洞察力超强的侦探，能够从你的话语中捕捉到这些微妙的暗示。


那么，大模型是如何做到这一点的呢？这就要说到它的“大脑”了。大模型的大脑由成千上万个小部件（称为神经网络节点）组成，它们一起工作，就像是在解决一个超级复杂的拼图。当你说一句话时，这些节点就会基于它们所学到的知识（记得那个装满书籍的图书馆吗？）来分析你的话，并试图找出你的真正意图。

大模型如何实现NLP中的意图识别，以及它的实现方式，以及面临的挑战都有哪些呢？

1. 大模型针对NLP实现意图识别的原理

大模型在NLP中实现意图识别，其原理可以比作一个超级复杂的“语言解码器”。这个解码器由成千上万个小部件组成，这些部件就是神经网络节点。这些节点通过模仿人脑的工作方式来处理信息。每当你说一句话或输入一段文本时，这些节点就像小侦探一样，开始工作，试图解析你的话里隐藏的真正意图。

这些节点是如何学会这些技能的呢？答案在于大量的训练数据。就像一个学徒通过观察和模仿来学习技能一样，这些神经网络节点通过分析大量的文本数据（比如书籍、文章、对话等）来学习语言的复杂性和微妙之处。通过这种方式，它们学会了不仅仅理解文字的字面意义，还能抓住语境、情感和隐含的意图。

![](https://p.ipic.vip/cmdbry.png)

2. 目前的实现方式

目前，大模型实现NLP意图识别的主要方式是通过深度学习。这涉及到构建和训练大型的神经网络，这些网络能够处理和分析大量的语言数据。这些模型通常需要大量的计算资源和数据来进行训练，以便它们能够理解和预测人类语言的复杂性。

这些模型通常被训练来执行多种语言任务，比如文本分类、情感分析、问题回答等。在这个过程中，模型学会了从语言中提取关键信息，并用这些信息来推断说话者或写作者的意图。

![](https://p.ipic.vip/ad711q.png)


3. 遇到的难题

尽管大模型在NLP意图识别方面取得了显著进展，但仍然面临一些挑战：

语境理解的局限性：虽然模型在理解语言方面变得越来越好，但它们仍然难以完全理解复杂的语境和隐含的意图，特别是在涉及到非常细微或文化特定的语境时。

偏见和不准确性：由于训练数据可能包含偏见或错误，模型有时会产生带有偏见或不准确的输出。这是一个持续的挑战，需要不断地优化模型和训练数据。

资源消耗：构建和训练这些大型模型需要大量的计算资源，这可能导致高能耗和环境影响。

泛化能力：虽然模型在训练数据上表现良好，但在面对全新的、未见过的数据或情况时，它们的表现可能会下降。

![](https://p.ipic.vip/b8dyk3.png)